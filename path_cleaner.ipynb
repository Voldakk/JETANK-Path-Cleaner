{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import threading\n",
    "import random\n",
    "import enum\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jetson.inference\n",
    "import jetson.utils\n",
    "net = jetson.inference.detectNet(argv=[\"--model=path_cleaner.onnx\", \"--labels=labels.txt\", \"--input-blob=input_0\", \"--output-cvg=scores\", \"--output-bbox=boxes\", \"--confidence=0.2\"], threshold=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The max driving speed of the robot\n",
    "robot_speed = 0.0\n",
    "horizon_offset = -0.15\n",
    "lane_offset_offset = 0\n",
    "missing_lane_offset = 0.2\n",
    "\n",
    "###############################################################################\n",
    "#  Overlay font and colors\n",
    "###############################################################################\n",
    "\n",
    "\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "color_overlay = (0, 255, 255)\n",
    "color_left_lane = (255, 0, 0)\n",
    "color_right_lane = (0, 0, 255)\n",
    "color_center_lane = (255, 0, 255)\n",
    "color_smooth_points = (255, 255, 0)\n",
    "\n",
    "line_thickness = 5\n",
    "circle_rad = 20\n",
    "overlay_text_spacing = 30\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "#  Lane detection\n",
    "###############################################################################\n",
    "\n",
    "\n",
    "# The reduction in resoultion for the image used for lane detection\n",
    "det_res_reduction = 8\n",
    "\n",
    "# The HSV color range for detecting the lanes (min values, max values)\n",
    "\n",
    "#lane_color_range = (np.array([0, 0, 140]), np.array([180, 20, 255])) # White\n",
    "lane_color_range = (np.array([0, 0, 180]), np.array([180, 40, 255])) # White\n",
    "\n",
    "erode_kernel = cv2.getStructuringElement(cv2.MORPH_RECT,(2,1))\n",
    "dilate_kernel = cv2.getStructuringElement(cv2.MORPH_RECT,(3,3))\n",
    "canny_low_threshold = 200\n",
    "canny_high_threshold = 400\n",
    "\n",
    "# The size of the sliding window for geting the smoothed stearing points\n",
    "sliding_window_size = 10\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "#  Target detection\n",
    "###############################################################################\n",
    "\n",
    "\n",
    "path_class = \"path\"\n",
    "target_class = \"wrapper\"\n",
    "\n",
    "# The HSV color range for detecting a picked up target (min values, max values)\n",
    "target_color_range = (np.array([0, 80, 0]), np.array([30, 255, 255])) # Yellow/orange\n",
    "\n",
    "# The desired position on the screen for a target to be able to pick it up\n",
    "desired_tagret_pos = np.array([0.45, 0.68])\n",
    "\n",
    "# The maximum error in relation to the desired tagret position before attempting to pick up the target\n",
    "tagret_pos_tol = 0.05\n",
    "\n",
    "# The maximum distance in screen space to a target before driving to it to pick it up\n",
    "# 0.0 = no targets are picked up\n",
    "# 0.5 = targets on the bottom half of the screen are picked up\n",
    "# 1.0 = all targets are picked up\n",
    "max_target_dist = 0.5\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "#  Servos\n",
    "###############################################################################\n",
    "\n",
    "\n",
    "# Servo ids\n",
    "class Servo(enum.Enum):\n",
    "    Rotation = 1\n",
    "    LowerArm = 2\n",
    "    UpperArm = 3\n",
    "    Claw = 4\n",
    "    Camera = 5 \n",
    "all_servo_ids = [s.value for s in Servo]\n",
    "\n",
    "# The min and max angle of each servo\n",
    "servo_angle_limit = {}\n",
    "servo_angle_limit[Servo.Rotation.value] = (-90, 90)\n",
    "servo_angle_limit[Servo.LowerArm.value] = (-90, 90)\n",
    "servo_angle_limit[Servo.UpperArm.value] = (-60, 90)\n",
    "servo_angle_limit[Servo.Claw.value]     = (-80,  0)\n",
    "servo_angle_limit[Servo.Camera.value]   = (-40, 25)\n",
    "\n",
    "# The initial angle each servo is set to at starup\n",
    "servo_angle_init = [-10, 0, 0, 0, 0, 25]\n",
    "arm_pos_init = (150, -50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RobotState(enum.Enum):\n",
    "    Idle         = 0\n",
    "    Detecting    = 1\n",
    "    Seeking      = 2\n",
    "    PickingUp    = 3\n",
    "    Disposing    = 4\n",
    "    PickUpFailed = 5\n",
    "    \n",
    "state = RobotState.Idle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clamp_signed(value, min_value, max_value):\n",
    "    # Returns the value clamed between the min value and max value keeping the sign of the original value.\n",
    "    return np.sign(value) * np.clip(abs(value), abs(min_value), abs(max_value))\n",
    "\n",
    "def crop_image(image, xmin, xmax, ymin, ymax):\n",
    "    # Returns the cropped rectangular region defined by the parameters.\n",
    "    # The parameters should be in the range (0, 1).\n",
    "    h, w, _ = image.shape\n",
    "    ymin = int(h * ymin)\n",
    "    ymax = int(h * ymax)\n",
    "    xmin = int(w * xmin)\n",
    "    xmax = int(w * xmax)\n",
    "    return image[ymin:ymax, xmin:xmax]\n",
    "\n",
    "class SlidingWindow:\n",
    "    # A sliding window implimentation for calculating the mean of the most recent N values.\n",
    "    def __init__(self, size):\n",
    "        self.values = []\n",
    "        self.size = size\n",
    "\n",
    "    def add(self, value):\n",
    "        self.values.append(value)\n",
    "        if len(self.values) > self.size:\n",
    "            self.values.pop(0)\n",
    "            \n",
    "    def mean(self):\n",
    "        return np.median(self.values)\n",
    "\n",
    "\n",
    "# The position of the next displayed text\n",
    "display_text_y = 0\n",
    "\n",
    "def display_text(overlay, text):\n",
    "    # Displays the text on the overlay stacked from the top left of the screen to the bottom\n",
    "    global display_text_y\n",
    "    display_text_y += overlay_text_spacing\n",
    "    cv2.putText(overlay, text, (0, display_text_y), font, 1.0, color_overlay, 2, cv2.LINE_AA)\n",
    "    \n",
    "def display_text_reset():\n",
    "    # Resets the position of the next displayed text, called each frame\n",
    "    global display_text_y\n",
    "    display_text_y = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cadddbad7e4d413fb625f74347f1dd90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'', height='616', width='820')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from jetbot import Camera, bgr8_to_jpeg\n",
    "\n",
    "import ipywidgets\n",
    "from IPython.display import display\n",
    "\n",
    "camera_width = 1640\n",
    "camera_height = 1232\n",
    "\n",
    "image_widget_scale = 0.5\n",
    "\n",
    "widget_width = int(camera_width * image_widget_scale)\n",
    "widget_height = int(camera_height * image_widget_scale)\n",
    "\n",
    "image_widget = ipywidgets.Image(width = widget_width, height = widget_height)\n",
    "display(image_widget)\n",
    "\n",
    "display_frame = None\n",
    "camera_lock = threading.Lock()\n",
    "display_lock = threading.Lock()\n",
    "\n",
    "def process_image(frame):\n",
    "    return frame\n",
    "\n",
    "def process_thread_func():\n",
    "    global process_thread_running\n",
    "    while process_thread_running:\n",
    "        time.sleep(0.01)\n",
    "        with camera_lock:\n",
    "            if camera.value is None:\n",
    "                continue\n",
    "            frame = camera.value.copy()\n",
    "        \n",
    "        try:\n",
    "            display_text_reset()\n",
    "            frame = process_image(frame)\n",
    "            frame = cv2.resize(frame, (widget_width, widget_height))\n",
    "            with display_lock:\n",
    "                display_frame = bgr8_to_jpeg(frame)\n",
    "                image_widget.value = display_frame\n",
    "                               \n",
    "        except Exception as e:\n",
    "            process_thread_running = False\n",
    "            camera.stop()\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeeded to open the port\n",
      "Succeeded to change the baudrate\n"
     ]
    }
   ],
   "source": [
    "# Init connection to servos and robot\n",
    "from SCSCtrl import TTLServo\n",
    "from jetbot import Robot\n",
    "robot = Robot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit the frequency of servo commands to avoid communication errors\n",
    "servoCtrlTime = 0.001\n",
    "\n",
    "# The number of steps to rotate the servos 1 degree\n",
    "steps_per_deg = (TTLServo.servoInputRange/TTLServo.servoAngleRange)\n",
    "\n",
    "# The current target value of each servo\n",
    "servo_angle_current = servo_angle_init.copy()\n",
    "\n",
    "def move_servo(servo, angle, speed=150):\n",
    "    # Moves the servo to the given angle\n",
    "    # Returns the estimated time needed for the move to complete using the given speed\n",
    "    \n",
    "    if type(servo) is Servo:\n",
    "        servo = int(servo.value)\n",
    "        \n",
    "    angle = int(np.clip(angle, servo_angle_limit[servo][0], servo_angle_limit[servo][1]))\n",
    "    \n",
    "    offset = angle - servo_angle_current[servo]\n",
    "    servo_angle_current[servo] = angle\n",
    "    \n",
    "    move_time = abs(offset*steps_per_deg) / speed\n",
    "    \n",
    "    TTLServo.servoAngleCtrl(servo, angle, 1, speed)\n",
    "    time.sleep(servoCtrlTime)\n",
    "    return move_time\n",
    "\n",
    "def move_servo_t(servo, angle, dt):\n",
    "    # Moves the servo to the given angle\n",
    "    # Returns the speed used for the move to complete in the given time\n",
    "    \n",
    "    if type(servo) is Servo:\n",
    "        servo = int(servo.value)\n",
    "        \n",
    "    angle = int(np.clip(angle, servo_angle_limit[servo][0], servo_angle_limit[servo][1]))\n",
    "    \n",
    "    offset = angle - servo_angle_current[servo]\n",
    "    servo_angle_current[servo] = angle\n",
    "    \n",
    "    speed = abs(offset*steps_per_deg) / dt\n",
    "    \n",
    "    TTLServo.servoAngleCtrl(servo, angle, 1, int(speed))\n",
    "    time.sleep(servoCtrlTime)\n",
    "    return speed\n",
    "    \n",
    "def reset_servo(servo, speed=150):\n",
    "    # Moves the servo to the initial position\n",
    "    # Returns the estimated time needed for the move to complete using the given speed\n",
    "    if type(servo) is Servo:\n",
    "        servo = int(servo.value)\n",
    "    return move_servo(servo, 0, speed)\n",
    "    \n",
    "def set_arm_pos(x, y):\n",
    "    # Moves the arm to the given position\n",
    "    la, ua = TTLServo.xyInput(x, y)\n",
    "    servo_angle_current[Servo.LowerArm.value] = int(la+90)\n",
    "    servo_angle_current[Servo.UpperArm.value] = int(-ua)\n",
    "    time.sleep(servoCtrlTime)\n",
    "    \n",
    "def set_arm_pos_t(x, y, dt):\n",
    "    # Moves the arm to the given position over the given duration\n",
    "    la, ua = TTLServo.xyInputSmooth(x, y, dt)\n",
    "    servo_angle_current[Servo.LowerArm.value] = int(la+90)\n",
    "    servo_angle_current[Servo.UpperArm.value] = int(-ua)\n",
    "    time.sleep(servoCtrlTime)\n",
    "\n",
    "# Set all servos to the init angle\n",
    "for s in all_servo_ids:\n",
    "    move_servo(s, servo_angle_init[s])\n",
    "\n",
    "if not arm_pos_init is None:\n",
    "    set_arm_pos(arm_pos_init[0], arm_pos_init[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_detection_mask(image, detections, ignore_detections, scale):\n",
    "    \"\"\"Masks regions of interest\"\"\"\n",
    "    \n",
    "    # Remove any regions outside of detections\n",
    "    mask = np.zeros_like(image)\n",
    "    for d in detections:\n",
    "        det_rect = np.array([[\n",
    "            (d.Left//scale, d.Top//scale),\n",
    "            (d.Right//scale, d.Top//scale),\n",
    "            (d.Right//scale, d.Bottom//scale),\n",
    "            (d.Left//scale, d.Bottom//scale),\n",
    "        ]], np.int32)\n",
    "        cv2.fillPoly(mask, det_rect, 255)\n",
    "    \n",
    "    # Remove any regions inside of ignore_detections\n",
    "    for d in ignore_detections:\n",
    "        det_rect = np.array([[\n",
    "            (d.Left//scale, d.Top//scale),\n",
    "            (d.Right//scale, d.Top//scale),\n",
    "            (d.Right//scale, d.Bottom//scale),\n",
    "            (d.Left//scale, d.Bottom//scale),\n",
    "        ]], np.int32)\n",
    "        cv2.fillPoly(mask, det_rect, 0)\n",
    "        \n",
    "    # Remove any regions in the top half of the image\n",
    "    height, width = image.shape\n",
    "    polygon = np.array([[\n",
    "        (0, 0),\n",
    "        (width, 0),\n",
    "        (width, height / 2),\n",
    "        (0, height / 2),\n",
    "    ]], np.int32)\n",
    "    cv2.fillPoly(mask, polygon, 0)\n",
    "    \n",
    "    return cv2.bitwise_and(image, mask)\n",
    "\n",
    "def detect_line_segments(edges):\n",
    "    \"\"\"Breakes the edge detected image into line segments\"\"\"\n",
    "    \n",
    "    # Distance precision in pixel, i.e. 1 pixel\n",
    "    rho = 1  \n",
    "    # Angular precision in radian, i.e. 1 degree\n",
    "    angle = np.pi / 180\n",
    "    # Minimal of votes\n",
    "    min_threshold = 10  \n",
    "    line_segments = cv2.HoughLinesP(edges, rho, angle, min_threshold, np.array([]), minLineLength=10, maxLineGap=15)\n",
    "    return line_segments\n",
    "\n",
    "def average_slope_intercept(image, line_segments, xmin, xmax, slope_dir):\n",
    "    \"\"\"\n",
    "    Calculates the average slope and intercept of multiple line segments.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    image\n",
    "        The image the line segments are from\n",
    "    line_segments\n",
    "        The line segments\n",
    "    xmin\n",
    "        [0..1] The min x value of the line segments to consider.\n",
    "    xmax\n",
    "        [0..1] The max x value of the line segments to consider.\n",
    "    slope_dir\n",
    "        1 or -1 to indicate the direction of the slope we want\n",
    "    \"\"\"\n",
    "    \n",
    "    if line_segments is None:\n",
    "        return None\n",
    "\n",
    "    height, width, _ = image.shape\n",
    "    xmin, xmax = xmin*width, xmax*width\n",
    "    fits = []\n",
    "    \n",
    "    for line_segment in line_segments:\n",
    "        for x1, y1, x2, y2 in line_segment:\n",
    "            if x1 == x2:\n",
    "                # Horizontal line\n",
    "                continue\n",
    "            if x1 <= xmax and x2 <= xmax and x1 >= xmin and x2 >= xmin:\n",
    "                if y2 < y1:\n",
    "                    y1, y2 = y2, y1\n",
    "                    x1, x2 = x2, x1\n",
    "                fit = np.polyfit((x1, x2), (y1, y2), 1)\n",
    "                slope = fit[0]\n",
    "                intercept = fit[1]\n",
    "                if slope*slope_dir > 0:\n",
    "                    fits.append((slope, intercept))\n",
    "    \n",
    "    fit_average = np.average(fits, axis=0) if len(fits) > 0 else None\n",
    "    return fit_average\n",
    "\n",
    "def get_intersect(rs, ri, ls, li):\n",
    "    '''\n",
    "    Calculates the intersection point of the two lines\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    rs & ls\n",
    "        The line slopes\n",
    "    ri & li\n",
    "        The line intercepts\n",
    "    '''\n",
    "    \n",
    "    xi = (ri-li) / (ls-rs+0.01)\n",
    "    yi = rs * xi + ri\n",
    "    return xi, yi\n",
    "\n",
    "def draw_lines(overlay, lines):\n",
    "    \"\"\"Draws the given lines on the overlay\"\"\"\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            for x1, y1, x2, y2 in line:\n",
    "                color = (random.randrange(255), random.randrange(255), random.randrange(255))\n",
    "                cv2.line(overlay, (x1*det_res_reduction, y1*det_res_reduction), (x2*det_res_reduction, y2*det_res_reduction), color, line_thickness)\n",
    "\n",
    "def get_line(image, slope, intercept):\n",
    "    \"\"\"Calculates the start and end points of the line stretching the width of the image\"\"\"\n",
    "    x0 = 0\n",
    "    x1 = image.shape[1]\n",
    "    \n",
    "    y0 = int(intercept + slope*x0)\n",
    "    y1 = int(intercept + slope*x1)\n",
    "    \n",
    "    return ((x0, y0), (x1, y1))\n",
    "\n",
    "def get_angle(p0, p1, p2):\n",
    "    \"\"\"Calcualtes the angle between the lines p0p1 and p1p2\"\"\"\n",
    "    v0 = np.array(p0) - np.array(p1)\n",
    "    v1 = np.array(p2) - np.array(p1)\n",
    "    angle = np.math.atan2(np.linalg.det([v0,v1]),np.dot(v0,v1))\n",
    "    if angle < 0:\n",
    "        angle += np.pi\n",
    "    return angle\n",
    "\n",
    "# Sliding windows for smoothing the c_x0 and c_xmax values\n",
    "c_x0_window = SlidingWindow(sliding_window_size)\n",
    "c_xmax_window = SlidingWindow(sliding_window_size)\n",
    "\n",
    "def lane_detect(image, overlay, detections, ignore_detections):\n",
    "    \"\"\"\n",
    "    Calculates the steering point in the horizon and the offset in the lane\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    image\n",
    "        The image to find the lanes on\n",
    "    overlay\n",
    "        The image text and lines are drawn on\n",
    "    detections\n",
    "        The detected lanes\n",
    "    ignore_detections\n",
    "        Regions we want to ignore\n",
    "    \"\"\"\n",
    "    \n",
    "    # Process image\n",
    "    resized = cv2.resize(image, (image.shape[1]//det_res_reduction, image.shape[0]//det_res_reduction))\n",
    "    \n",
    "    hsv = cv2.cvtColor(resized, cv2.COLOR_BGR2HSV)\n",
    "    mask = cv2.inRange(hsv, lane_color_range[0], lane_color_range[1])\n",
    "    \n",
    "    mask = cv2.erode(mask, erode_kernel, iterations=2)\n",
    "    mask = cv2.dilate(mask, dilate_kernel, iterations=1)\n",
    "    \n",
    "    edges = cv2.Canny(mask, canny_low_threshold, canny_high_threshold)\n",
    "    \n",
    "    edges = apply_detection_mask(edges, detections, ignore_detections, det_res_reduction)\n",
    "    \n",
    "    # Get lines\n",
    "    line_segments = detect_line_segments(edges)\n",
    "    \n",
    "    # Draw the found line segments\n",
    "    draw_lines(overlay, line_segments)\n",
    "    \n",
    "    step = 0.2\n",
    "    l, r = None, None\n",
    "    stop = 0.7\n",
    "    for x in np.arange(0, 1, step):\n",
    "        if x >= stop:\n",
    "            break\n",
    "        if l is None:\n",
    "            l = average_slope_intercept(resized, line_segments, 0, x, -1)\n",
    "        if r is None:\n",
    "            r = average_slope_intercept(resized, line_segments, 1-x, 1, 1)\n",
    "        if (not l is None or not r is None) and stop == 1:\n",
    "            stop = 1-x\n",
    "        if not l is None and not r is None:\n",
    "            break\n",
    "    display_text(overlay, f'Stop: {stop}')\n",
    "    \n",
    "    if l is None and r is None:\n",
    "        return image, 0, 0, 0\n",
    "    \n",
    "    rs, ri = r if not r is None else (0, 0)\n",
    "    ls, li = l if not l is None else (0, 0)\n",
    "    ri, li = ri*det_res_reduction, li*det_res_reduction\n",
    "    \n",
    "    l_line = get_line(image, ls, li)\n",
    "    r_line = get_line(image, rs, ri)\n",
    "    \n",
    "    # Calculate center lane\n",
    "    xi, yi = get_intersect(rs, ri, ls, li)\n",
    "    angr = get_angle((1000000, yi), (xi, yi), r_line[1])\n",
    "    angl = get_angle((1000000, yi), (xi, yi), l_line[1])\n",
    "    angc = (angl+angr) / 2\n",
    "    \n",
    "    slope = np.sin(angc)/np.cos(angc)\n",
    "    if r is None or l is None:\n",
    "        slope = -slope\n",
    "    \n",
    "    c_y0 = image.shape[0]\n",
    "    c_x0 = xi + (c_y0 / slope) if not slope == 0 else 0\n",
    "    c_x0 = np.clip(c_x0, -1000000, 1000000)\n",
    "    \n",
    "    c_ymax = 0\n",
    "    c_xmax = xi + (c_ymax / slope) if not slope == 0 else 0\n",
    "    c_xmax = np.clip(c_xmax, -1000000, 1000000)\n",
    "    \n",
    "    # Calculate lane offset\n",
    "    c_x0_window.add(c_x0)\n",
    "    mean_c_x0 = c_x0_window.mean()\n",
    "    lane_offset = 2*mean_c_x0 / image.shape[1] - 1\n",
    "    \n",
    "    # Calculate horizon\n",
    "    c_xmax_window.add(c_xmax)\n",
    "    mean_c_xmax = c_xmax_window.mean()\n",
    "    horizon = 2*mean_c_xmax / image.shape[1] - 1\n",
    "    \n",
    "    # Draw the lanes\n",
    "    cv2.line(overlay, l_line[0], l_line[1], color_left_lane, line_thickness)\n",
    "    cv2.line(overlay, r_line[0], r_line[1], color_right_lane, line_thickness)\n",
    "    \n",
    "    # Draw center lines\n",
    "    cv2.circle(overlay, (int(c_x0), int(c_y0)), radius=circle_rad, color=color_center_lane, thickness=-1)\n",
    "    cv2.circle(overlay, (int(c_xmax), int(c_ymax)), radius=circle_rad, color=color_center_lane, thickness=-1)\n",
    "    cv2.line(overlay, (int(c_xmax), int(c_ymax)), (int(c_x0), int(c_y0)), color_center_lane, line_thickness)\n",
    "    \n",
    "    cv2.circle(overlay, (int(mean_c_x0), c_y0), radius=circle_rad, color=color_smooth_points, thickness=-1)\n",
    "    cv2.circle(overlay, (int(mean_c_xmax), 0), radius=circle_rad, color=color_smooth_points, thickness=-1)\n",
    "    cv2.line(overlay, (int(mean_c_xmax), 0), (int(mean_c_x0), c_y0), color_smooth_points, line_thickness)\n",
    "    \n",
    "    mlo = missing_lane_offset if r is None else (-missing_lane_offset if l is None else 0)\n",
    "    display_text(overlay, f'MLO: {mlo:.2f}')\n",
    "    return image, horizon + horizon_offset + mlo, lane_offset + lane_offset_offset+mlo*4, 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def go_to_target(overlay, pos, desired_pos, speed):\n",
    "    delta = desired_pos - pos\n",
    "    \n",
    "    l, r = 0, 0\n",
    "    \n",
    "    r += delta[0]\n",
    "    l -= delta[0]\n",
    "        \n",
    "    r += delta[1]\n",
    "    l += delta[1]\n",
    "    \n",
    "    display_text(overlay, f'Motor power: ({delta[0]:.2f}, {delta[1]:.2f})')\n",
    "    \n",
    "    if abs(l) < tagret_pos_tol and abs(r) < tagret_pos_tol:\n",
    "        robot.stop()\n",
    "        return True\n",
    "    \n",
    "    l, r = clamp_signed(l*speed*2, 0.15, 1), clamp_signed(r*speed*2, 0.15, 1)\n",
    "    robot.set_motors(l, r)\n",
    "    return False\n",
    "\n",
    "def ywait(t):\n",
    "    start_time = time.time()\n",
    "    while (time.time() - start_time) < t:\n",
    "        yield False\n",
    "    \n",
    "def grab_target(center):\n",
    "    ypos = np.interp(center[1], [0.65, 0.70], [160, 140])\n",
    "    \n",
    "    set_arm_pos_t(int(ypos), -160, 1)\n",
    "    yield from ywait(1)\n",
    "    \n",
    "    move_servo_t(Servo.Claw, -80, 1.5)\n",
    "    set_arm_pos_t(int(ypos), -150, 1.5)\n",
    "    yield from ywait(1.5)\n",
    "        \n",
    "    set_arm_pos_t(150, -60, 1)\n",
    "    yield from ywait(1)\n",
    "    yield True\n",
    "    \n",
    "def failed_grab():\n",
    "    dt = move_servo(Servo.Claw, 0, 300)\n",
    "    yield from ywait(dt)\n",
    "    yield True\n",
    "\n",
    "def drop_target():\n",
    "    dt = move_servo(Servo.Rotation, -90, 300)\n",
    "    yield from ywait(dt)\n",
    "    \n",
    "    set_arm_pos_t(150, -150, 1)\n",
    "    yield from ywait(1)\n",
    "    \n",
    "    dt = move_servo(Servo.Claw, 0, 300)\n",
    "    yield from ywait(dt)\n",
    "    \n",
    "    set_arm_pos_t(150, -50, 1)\n",
    "    yield from ywait(1)\n",
    "    \n",
    "    dt = reset_servo(Servo.Rotation, 300)\n",
    "    yield from ywait(dt)\n",
    "    yield True\n",
    "\n",
    "grab_gen = None\n",
    "drop_gen = drop_target()\n",
    "failed_grab_gen = failed_grab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_pos = np.zeros(2)\n",
    "target_index = -1\n",
    "\n",
    "def detect(image):\n",
    "    image_cuda = jetson.utils.cudaFromNumpy(image)\n",
    "    detections = net.Detect(image_cuda)\n",
    "    return detections\n",
    "    \n",
    "def drive(overlay, horizon, offset, speed):   \n",
    "    l = np.interp(horizon, [-2, -1, -0.5, 0, 1], [-0.5, 0.2, 0.5, 0.8, 1])\n",
    "    r = np.interp(horizon, [-1, 0, 0.5, 1, 2], [1, 0.8, 0.5, 0.2, -0.5])\n",
    "    \n",
    "    offset_coef = 1\n",
    "    \n",
    "    l = l + np.interp(offset, [-1, 0, 1], [-0.5, 0.1, 1]) * offset_coef\n",
    "    r = r + np.interp(offset, [-1, 0, 1], [1, 0.1, -0.5]) * offset_coef\n",
    "    \n",
    "    m = max(abs(l), abs(r))\n",
    "    l, r = l/m, r/m\n",
    "    \n",
    "    display_text(overlay, f'Motor balance: ({l:.2f}, {r:.2f})')\n",
    "    \n",
    "    l, r = clamp_signed(l*speed, 0.1, 1), clamp_signed(r*speed, 0.1, 1)\n",
    "    robot.set_motors(l, r)\n",
    "    \n",
    "def has_grabbed_target(image):\n",
    "    crop = crop_image(image, 0.38, 0.56, 0, 0.2)\n",
    "    hsv = cv2.cvtColor(crop, cv2.COLOR_BGR2HSV)\n",
    "    mask = cv2.inRange(hsv, target_color_range[0], target_color_range[1])\n",
    "    mask = cv2.dilate(mask, dilate_kernel, iterations=10)\n",
    "    cnts = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[-2]\n",
    "\n",
    "    if len(cnts) == 0:\n",
    "        return False\n",
    "    \n",
    "    c = max(cnts, key=cv2.contourArea)\n",
    "    area = cv2.contourArea(c)\n",
    "    return area > 5000\n",
    "\n",
    "def process_image(image):\n",
    "    global state, target_pos, grab_gen, drop_gen, failed_grab_gen, target_index\n",
    "    \n",
    "    isize = (image.shape[1], image.shape[0])\n",
    "    \n",
    "    overlay = np.zeros_like(image)\n",
    "    display_text(overlay, state.name)\n",
    "\n",
    "    if state is RobotState.Idle:\n",
    "        robot.stop()\n",
    "        reset_servo(Servo.Rotation, 150)\n",
    "    \n",
    "    if state is RobotState.Detecting or state is RobotState.Seeking:\n",
    "        detections = detect(image)\n",
    "        for d in detections:\n",
    "            class_name = net.GetClassDesc(d.ClassID)\n",
    "            left = int(np.clip(d.Left, 0, isize[0]))\n",
    "            right = int(np.clip(d.Right, 0, isize[0]))\n",
    "            top = int(np.clip(d.Top, 0, isize[1]))\n",
    "            bottom = int(np.clip(d.Bottom, 0, isize[1]))\n",
    "            cv2.rectangle(overlay, (left, top), (right, bottom), color_overlay, 1)\n",
    "            cv2.putText(overlay, f'{class_name} {(d.Confidence*100):.1f}%', (left, top-40), font, 1.0, color_overlay, 2, cv2.LINE_AA)\n",
    "            cv2.putText(overlay, f'({(d.Center[0]/isize[0]):.2f}, {(d.Center[1]/isize[1]):.2f}) {d.Area:.0f}', (left, top-5), font, 1.0, color_overlay, 2, cv2.LINE_AA)\n",
    "        target_detections = [d for d in detections if net.GetClassDesc(d.ClassID) == target_class]\n",
    "        path_detections = [d for d in detections if net.GetClassDesc(d.ClassID) == path_class]\n",
    "        \n",
    "        target_index = -1\n",
    "        if len(target_detections) > 0:\n",
    "            index, target = max(enumerate(target_detections), key=lambda d: d[1].Bottom)\n",
    "            if target.Bottom >= int(isize[1] * (1-max_target_dist)):\n",
    "                target_index = index\n",
    "                display_text(overlay, f'{target_index}, {target_detections[target_index].Bottom}')\n",
    "    else:\n",
    "        target_detections = []\n",
    "        path_detections = []\n",
    "    \n",
    "    if state is RobotState.Detecting:\n",
    "        image, horizon, lane_offset, speed = lane_detect(image, overlay, path_detections, target_detections)\n",
    "        display_text(overlay, f'Horizon: {horizon:.2f}')\n",
    "        display_text(overlay, f'Lane offset: {lane_offset:.2f}')\n",
    "        drive(overlay, horizon, lane_offset, speed*robot_speed)\n",
    "        \n",
    "        if target_index != -1:\n",
    "            state = RobotState.Seeking\n",
    "    \n",
    "    if state is RobotState.Seeking:\n",
    "        if target_index != -1:\n",
    "            d = target_detections[target_index]\n",
    "            target_pos = np.array([d.Center[0] / isize[0], d.Center[1] / isize[1]])\n",
    "            at_target = go_to_target(overlay, target_pos, desired_tagret_pos, robot_speed)\n",
    "            if at_target:\n",
    "                state = RobotState.PickingUp\n",
    "                pass\n",
    "        else:\n",
    "            state = RobotState.Detecting\n",
    "            \n",
    "    if state is RobotState.PickingUp:    \n",
    "        if grab_gen is None:\n",
    "            grab_gen = grab_target(target_pos)\n",
    "        if next(grab_gen):\n",
    "            grab_gen = None\n",
    "            if has_grabbed_target(image):\n",
    "                state = RobotState.Disposing\n",
    "            else:\n",
    "                state = RobotState.PickUpFailed\n",
    "    \n",
    "    if state is RobotState.PickUpFailed:\n",
    "        if next(failed_grab_gen):\n",
    "            failed_grab_gen = failed_grab()\n",
    "            state = RobotState.Detecting\n",
    "    \n",
    "    if state is RobotState.Disposing:\n",
    "        if next(drop_gen):\n",
    "            drop_gen = drop_target()\n",
    "            state = RobotState.Detecting\n",
    "    \n",
    "    if image.shape != overlay.shape:\n",
    "        image = cv2.resize(image, (overlay.shape[1], overlay.shape[0]))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
    "    return cv2.addWeighted(image, 1, overlay, 1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Switch states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = RobotState.Detecting\n",
    "speed = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = RobotState.Detecting\n",
    "speed = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = RobotState.Idle\n",
    "speed = 0.0\n",
    "robot.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manual control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot.forward(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot.backward(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot.left(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start / Stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Re)start the camera and the image processing thread\n",
    "\n",
    "try:\n",
    "    camera.stop()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    process_thread_running = False\n",
    "    if process_thread.isAlive():\n",
    "        process_thread.join()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "camera = Camera.instance(width=camera_width, height=camera_height)\n",
    "process_thread_running = True\n",
    "process_thread = threading.Thread(target=process_thread_func, daemon=True)\n",
    "process_thread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop the camera and the image processing thread\n",
    "process_thread_running = False\n",
    "if process_thread.isAlive():\n",
    "    process_thread.join()\n",
    "camera.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
